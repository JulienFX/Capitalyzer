{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0122169",
   "metadata": {},
   "source": [
    "## Script de création du dataset Linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abfca18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 mails exportés vers data_labeled_linkedin.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from base64 import urlsafe_b64decode\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
    "OUTPUT_FILE = \"data_labeled_linkedin.xlsx\"\n",
    "\n",
    "QUERY = 'subject:\"votre candidature a été envoyée à\"'\n",
    "\n",
    "# ============================================================\n",
    "# AUTHENTIFICATION GMAIL\n",
    "# ============================================================\n",
    "\n",
    "def get_authenticated_service():\n",
    "    creds = None\n",
    "\n",
    "    if os.path.exists(\"token.json\"):\n",
    "        creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                \"gmail_credentials.json\",\n",
    "                SCOPES\n",
    "            )\n",
    "            creds = flow.run_local_server(port=0)\n",
    "\n",
    "        with open(\"token.json\", \"w\") as token:\n",
    "            token.write(creds.to_json())\n",
    "\n",
    "    return build(\"gmail\", \"v1\", credentials=creds)\n",
    "\n",
    "# ============================================================\n",
    "# UTILITAIRES\n",
    "# ============================================================\n",
    "\n",
    "def decode_body(data):\n",
    "    if not data:\n",
    "        return \"\"\n",
    "    return urlsafe_b64decode(data).decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "def clean_html(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for tag in soup([\"script\", \"style\", \"img\", \"footer\", \"header\", \"svg\"]):\n",
    "        tag.decompose()\n",
    "    return soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "def extract_message_text(payload):\n",
    "    mime_type = payload.get(\"mimeType\", \"\")\n",
    "\n",
    "    if mime_type == \"text/plain\":\n",
    "        return decode_body(payload.get(\"body\", {}).get(\"data\", \"\"))\n",
    "\n",
    "    if mime_type == \"text/html\":\n",
    "        html = decode_body(payload.get(\"body\", {}).get(\"data\", \"\"))\n",
    "        return clean_html(html)\n",
    "\n",
    "    if mime_type.startswith(\"multipart/\"):\n",
    "        for part in payload.get(\"parts\", []):\n",
    "            text = extract_message_text(part)\n",
    "            if text:\n",
    "                return text\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def get_header(headers, name):\n",
    "    return next(\n",
    "        (h[\"value\"] for h in headers if h[\"name\"].lower() == name.lower()),\n",
    "        \"\"\n",
    "    )\n",
    "\n",
    "def extract_email(from_header):\n",
    "    \"\"\"\n",
    "    Extrait uniquement l'adresse email depuis :\n",
    "    'LinkedIn Jobs <jobs-noreply@linkedin.com>'\n",
    "    \"\"\"\n",
    "    if not from_header:\n",
    "        return \"\"\n",
    "\n",
    "    match = re.search(r\"<([^>]+)>\", from_header)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "\n",
    "    return from_header.strip()\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    service = get_authenticated_service()\n",
    "\n",
    "    all_rows = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        response = service.users().messages().list(\n",
    "            userId=\"me\",\n",
    "            q=QUERY,\n",
    "            maxResults=100,\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        messages = response.get(\"messages\", [])\n",
    "        if not messages:\n",
    "            break\n",
    "\n",
    "        for msg in messages:\n",
    "            msg_detail = service.users().messages().get(\n",
    "                userId=\"me\",\n",
    "                id=msg[\"id\"],\n",
    "                format=\"full\"\n",
    "            ).execute()\n",
    "\n",
    "            payload = msg_detail.get(\"payload\", {})\n",
    "            headers = payload.get(\"headers\", [])\n",
    "\n",
    "            subject = get_header(headers, \"Subject\")\n",
    "            raw_from = get_header(headers, \"From\")\n",
    "            sender = extract_email(raw_from)\n",
    "\n",
    "            internal_date = int(msg_detail.get(\"internalDate\", 0))\n",
    "            date = datetime.fromtimestamp(internal_date / 1000).strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "            body = extract_message_text(payload)\n",
    "\n",
    "            all_rows.append({\n",
    "                \"subject\": subject,\n",
    "                \"body\": body,\n",
    "                \"from\": sender,\n",
    "                \"date\": date,\n",
    "                \"label\": 1\n",
    "            })\n",
    "\n",
    "        next_page_token = response.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    df.to_excel(OUTPUT_FILE, index=False)\n",
    "\n",
    "    print(f\"{len(df)} mails exportés vers {OUTPUT_FILE}\")\n",
    "\n",
    "# ============================================================\n",
    "# ENTRY POINT\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abebe209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
